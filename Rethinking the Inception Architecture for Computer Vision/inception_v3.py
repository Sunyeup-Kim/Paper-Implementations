# -*- coding: utf-8 -*-
"""Inception V2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AdCk0KXtwTVKHomcHkBbu6_Qse1QhYfB
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from keras.utils.vis_utils import plot_model
from keras import models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import os
import datetime

def inception_module_fig5(input):
  # figure 5 in paper
  # shape might be 3-dimension
  layer1 = layers.Conv2D(64, (1, 1), activation="relu", padding="same")(input)
  layer1 = layers.Conv2D(96, (3, 3), activation="relu", padding="same")(layer1)
  layer1 = layers.Conv2D(96, (3, 3), activation="relu", padding="same")(layer1)

  layer2 = layers.Conv2D(48, (1, 1), activation="relu", padding="same")(input)
  layer2 = layers.Conv2D(64, (3, 3), activation="relu", padding="same")(layer2)
  
  layer3 = layers.AveragePooling2D(3, strides=1, padding="same")(input)
  layer3 = layers.Conv2D(32, (1, 1), activation="relu", padding="same")(layer3)  

  layer4 = layers.Conv2D(64, (1, 1), activation="relu", padding="same")(input)

  module = layers.concatenate([layer1, layer2, layer3, layer4])

  # concatenate 사용시 인지사항
  # It takes as input a list of tensors, all of the same shape except for the concatenation axis, and returns a single tensor that is the concatenation of all inputs.
  # axis = -1이 default다. 즉, 가장 마지막 값이 채널 숫자를 제외하곤 모양이 맞아야 한다는 것이다.

  return module


def inception_module_fig6(input):
  # figure 6 in paper
  # shape might be 3-dimension

  layer1 = layers.Conv2D(128, (1, 1), activation="relu", padding="same")(input)
  layer1 = layers.Conv2D(128, (1, 7), activation="relu", padding="same")(layer1)
  layer1 = layers.Conv2D(128, (7, 1), activation="relu", padding="same")(layer1)
  layer1 = layers.Conv2D(128, (1, 7), activation="relu", padding="same")(layer1)
  layer1 = layers.Conv2D(128, (7, 1), activation="relu", padding="same")(layer1)

  layer2 = layers.Conv2D(128, (1, 1), activation="relu", padding="same")(input)
  layer2 = layers.Conv2D(128, (1, 7), activation="relu", padding="same")(layer2)
  layer2 = layers.Conv2D(192, (7, 1), activation="relu", padding="same")(layer2)

  
  layer3 = layers.MaxPooling2D((1, 1), padding="same")(input)
  layer3 = layers.Conv2D(192, (1, 1), activation="relu", padding="same")(layer3)
  
  layer4 = layers.MaxPooling2D((3, 3), strides=1, padding="same")(input)

  module = layers.concatenate([layer1, layer2, layer3, layer4])

  return module

def inception_module_fig7(input):
  # figure 7 in paper
  # shape might be 3-dimension

  layer1 = layers.Conv2D(448, (1, 1), activation="relu", padding="same")(input)
  layer1 = layers.Conv2D(384, (3, 3), activation="relu", padding="same")(layer1)

  layer1_1 = layers.Conv2D(384, (1, 3), activation="relu", padding="same")(layer1)
  layer1_2 = layers.Conv2D(384, (3, 1), activation="relu", padding="same")(layer1)

  layer2 = layers.Conv2D(384, (1, 1), activation="relu", padding="same")(input)

  layer2_1 = layers.Conv2D(384, (1, 3), activation="relu", padding="same")(layer1)
  layer2_2 = layers.Conv2D(384, (3, 1), activation="relu", padding="same")(layer1)
  
  layer3 = layers.MaxPooling2D((3, 3), strides = 1, padding="same")(input)
  layer3 = layers.Conv2D(192, (1, 1), activation="relu", padding="same")(layer3)

  layer4 = layers.Conv2D(320, (1, 1), activation="relu", padding="same")(input)

  module = layers.concatenate([layer1_1, layer1_2, layer2_1, layer2_2, layer3, layer4])

  return module

def reduction_module(input, filter_channels):
  filter_b1, filter_b2 = filter_channels

  layer1 = layers.Conv2D(filter_b1[0], (1, 1), activation="relu", padding="same")(input)
  layer1 = layers.Conv2D(filter_b1[1], (3, 3), strides=1, activation="relu", padding="same")(layer1)
  layer1 = layers.Conv2D(filter_b1[2], (3, 3), strides=2, activation="relu", padding="same")(layer1)

  layer2 = layers.Conv2D(filter_b2[0], (1, 1), activation="relu", padding="same")(input)
  layer2 = layers.Conv2D(filter_b2[1], (3, 3), strides=2, activation="relu", padding="same")(layer2)

  layer3 = layers.MaxPooling2D((3, 3), strides=2, padding="same")(input)

  module = layers.concatenate([layer1, layer2, layer3])

  return module

def inception_v2(input, class_n):


  x = layers.Conv2D(32, (3, 3), strides=2)(input)
  x = layers.Conv2D(32, (3, 3))(x)
  x = layers.Conv2D(64, (3, 3), padding="same")(x)


  x = layers.MaxPooling2D(64, (3, 3))(x)
  

  x = layers.Conv2D(80, (3, 3), padding="valid")(x)
  x = layers.Conv2D(192, (3, 3), strides=2, padding="same")(x)
  x = layers.Conv2D(288, (3, 3), padding="same")(x)


  x = inception_module_fig5(x)
  x = inception_module_fig5(x)
  x = inception_module_fig5(x)
  

  x = reduction_module(x, [[64, 96, 96], [256, 384]])
  

  x = inception_module_fig6(x)
  x = inception_module_fig6(x)
  x = inception_module_fig6(x)
  x = inception_module_fig6(x)
  x = inception_module_fig6(x)
  

  x = reduction_module(x, [[128, 192, 192], [192, 320]])
  

  x = inception_module_fig7(x)
  x = inception_module_fig7(x)


  x = layers.GlobalAveragePooling2D()(x)
  x = layers.Dropout(0.7)(x)


  output = layers.Dense(class_n, activation="softmax")(x)

  model = keras.Model(inputs=input, outputs=output)

  return model

input = keras.Input((299, 299, 3))
model = inception_v2(input, 2)

model.summary()

keras.utils.plot_model(model, show_shapes=True)

model.compile(optimizer="rmsprop", loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['acc'])

from google.colab import drive
drive.mount('/content/drive')

batch_size = 64
epochs = 10
IMG_HEIGHT = 299
IMG_WIDTH = 299
model_name = "homework"      #plot이나 h5 저장 시 사용할 이름

PATH = "/content/drive/My Drive/Colab Notebooks/데문해2/data/cats_and_dogs_filtered/"

### 2. 데이터셋 로드
# training: 2000 (cat:1000, dog:1000) / Validation: 1000 (cat:500/ dog:500) / Test : 2 persons

train_dir = os.path.join(PATH, 'train')
val_dir = os.path.join(PATH, 'validation')
test_dir = os.path.join(PATH, 'test')

train_num = len(os.listdir(os.path.join(train_dir, 'cats'))) + len(os.listdir(os.path.join(train_dir, 'dogs')))
val_num = len(os.listdir(os.path.join(val_dir, 'cats'))) + len(os.listdir(os.path.join(val_dir, 'dogs')))
test_num = len(os.listdir(os.path.join(test_dir, 'picture')))

print('Train 이미지 개수:', train_num)
print('Validataion 이미지 개수:', val_num)
print('Test 이미지 개수:', test_num)



### 3. 데이터셋 제너레이터 생성 (Data Augmentation 포함)
train_datagen = ImageDataGenerator(rescale=1./ 255)
val_datagen = ImageDataGenerator(rescale=1. / 255)
test_datagen = ImageDataGenerator(rescale=1. / 255)

# 하나의 pipe-line으로 경로 하위 파일을 label로, 그 아래 파일을 각 데이터라고 flow_from_directory 함수가 추측한다
train_generator = train_datagen.flow_from_directory(train_dir,
                                                    target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                    batch_size=batch_size,
                                                    # shuffle=True,
                                                    class_mode='binary',
                                                    )
val_generator = val_datagen.flow_from_directory(val_dir,
                                                target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                batch_size=batch_size,
                                                class_mode='binary',
                                                )

print("\n 모델을 트레이닝합니다 :")
history = model.fit_generator(train_generator,
                              steps_per_epoch = train_num//batch_size,
                              epochs=epochs,
                              validation_data=val_generator,
                              validation_steps = val_num//batch_size,
                              verbose=1
                              )

### 7. 결과 출력
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(len(acc))

